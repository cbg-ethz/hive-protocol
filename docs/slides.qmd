---
title: "Modern Python for Computational Biology"
subtitle: "⬢ The Hive Protocol ⬢"
author: "CBG Retreat 2026"
date: "22 January 2026"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    transition: fade
    width: 1600
    height: 900
    footer: "⬢ Hive Protocol ⬢ CBG Retreat 2026 | ETH Zurich"
execute:
  echo: true
  eval: false
---

## {background-color="#2E86AB"}

::: {.r-fit-text}
What if every project started with tests, docs, and CI already working?
:::

. . .

**Fork this repo. Delete the TODO. Ship research software.**

. . .

::: {.center}
[⬢ HIVE-PROTOCOL ⬢]{.hive-brand .hive-brand-large}
:::


## The Problem

::: {.columns}
::: {.column width="55%"}
![](images/xkcd-fixing-problems.png){height="400px"}
:::

::: {.column width="45%"}
### The recursive refactor trap

- "Just one quick fix..."
- No tests → afraid to change code
- No types → bugs hide until runtime
- No CI → "works on my machine"
- No structure → rewrite from scratch

### The real cost

- **Papers** with broken code
- **Results** that can't be reproduced
- **Time** lost to environment hell
:::
:::

# Foundations {background-color="#2E86AB"}

## The 2026 Landscape

The Python ecosystem has matured. **Use the modern tools.**

| Old Way | Modern Way | Benefit |
|---------|------------|---------|
| pip + requirements.txt | **pixi** | 10-100x faster, handles conda + PyPI |
| Black + flake8 + isort | **Ruff** | Single tool, 30-100x faster |
| pandas for everything | **Polars** | 5-50x faster for large data |
| Jupyter notebooks | **Quarto** | Clean git diffs, reproducible |
| Manual testing | **pytest + Hypothesis** | Property-based testing |
| Manual config validation | **Pydantic** | Automatic validation, serialization |

## Our Toolkit

::: {.honeycomb}
::: {.hex-row .row-top}
::: {.hex-item}
![](images/logos/pixi.svg){height="45px"}
Pixi
:::
::: {.hex-item}
![](images/logos/ruff.svg){height="45px"}
Ruff
:::
::: {.hex-item}
![](images/logos/polars.svg){height="45px"}
Polars
:::
::: {.hex-item}
![](images/logos/quarto.svg){height="45px"}
Quarto
:::
:::
::: {.hex-row .row-middle}
::: {.hex-item}
![](images/logos/pytest.svg){height="45px"}
Pytest
:::
::: {.hex-item}
![](images/logos/hypothesis.svg){height="45px"}
Hypothesis
:::
::: {.hex-item}
![](images/logos/pydantic.svg){height="45px"}
Pydantic
:::
:::
::: {.hex-row .row-bottom}
::: {.hex-item}
![](images/logos/mypy.svg){height="45px"}
mypy
:::
::: {.hex-item}
![](images/logos/pyright.svg){height="45px"}
Pyright
:::
::: {.hex-item}
![](images/logos/interrogate.svg){height="45px"}
Interrogate
:::
:::
:::

## Why Pixi?

::: {.columns}
::: {.column width="55%"}
### Bioinformatics needs conda

- samtools, bedtools, bcftools
- Many tools are conda-only
- PyPI alone isn't enough

### The alternatives

| Tool | Conda | PyPI | Speed | Lock files |
|------|:-----:|:----:|:-----:|:----------:|
| **conda** | Yes | Limited | Slow | No |
| **poetry** | No | Yes | Medium | Yes |
| **uv** | No | Yes | Fast | Yes |
| **pixi** | Yes | Yes | Fast | Yes |

:::

::: {.column width="45%"}
### Why we chose Pixi

```bash
# Install everything in seconds
pixi install

# Run commands in the environment
pixi run test
pixi run lint
```

### Speed comparison

```
conda create ... → 5 min
poetry install → 2 min
uv pip install → 30 sec
pixi install → 30 sec
  (+ conda packages!)
```
:::
:::

## Pixi: Community Support

::: {.columns}
::: {.column width="33%"}
![](images/conda-forge-pixi.png){height="320px"}
:::
::: {.column width="33%"}
![](images/anaconda-pixi.png){height="320px"}
:::
::: {.column width="33%"}
![](images/pixi-star-history.png){height="320px"}
:::
:::

Endorsed by **conda-forge** and **Anaconda** — the future of conda environments.

::: {.callout-note}
**Free for research:** Pixi is BSD3-licensed. No fees, no restrictions on academic use.
:::

## Why Ruff?

::: {.columns}
::: {.column width="50%"}
### One tool replaces many

- Black (formatting)
- flake8 (linting)
- isort (import sorting)
- pyupgrade (syntax updates)
- And 700+ lint rules

### Written in Rust

30-100x faster than Python equivalents
:::

::: {.column width="50%"}
### Demo

```bash
# Check for issues
pixi run ruff check src/

# Auto-fix everything
pixi run ruff check --fix src/
pixi run ruff format src/
```

One command. Done.
:::
:::

## Repository Structure

```
hive-protocol/
├── src/hive_protocol/       # Source code (src layout)
│   ├── inference/           # Kalman filter + diagnostics
│   └── data/                # Data simulation
├── tests/                   # pytest + Hypothesis tests
├── notebooks/               # Quarto tutorials
├── workflow/                # Snakemake pipeline
├── docs/                    # Workshop materials
├── pyproject.toml           # Single source of truth
└── pixi.toml                # Environment specification
```

**Key principle:** `pyproject.toml` is the single source of truth for your project.

## Hands-on: Setup

```bash
# Clone the repository
git clone https://github.com/cbg-ethz/hive-protocol.git
cd hive-protocol

# Install pixi (if needed)
curl -fsSL https://pixi.sh/install.sh | bash

# Set up environment
pixi install

# Verify it works
pixi run test
```

**Goal:** Everyone has a working environment.

# Example Content: Bayesian Kalman Filter {background-color="#A23B72"}

## The Example: State-Space Model

::: {.columns}
::: {.column width="50%"}
### The problem

Estimate hidden states from noisy observations using PyMC.

```python
from hive_protocol.data import simulate_noisy_trajectory
from hive_protocol.inference import fit_kalman_filter

# Simulate and fit
states, obs = simulate_noisy_trajectory(n_steps=50)
model, trace = fit_kalman_filter(obs)
```

*This is example content—replace with your domain logic.*
:::

::: {.column width="50%"}
### Always check diagnostics

- **R-hat** < 1.01: Chains converged
- **ESS** > 400: Enough samples
- **Divergences** = 0: No issues

> "If you don't check diagnostics, you don't have results."
:::
:::

# Testing & Type Safety {background-color="#A23B72"}

## Type Checking: mypy vs Pyright

::: {.columns}
::: {.column width="50%"}
### Why type hints?

```python
# Without types - what does this return?
def process(data, threshold):
    return [x for x in data if x > threshold]

# With types - crystal clear
def process(
    data: list[float],
    threshold: float,
) -> list[float]:
    return [x for x in data if x > threshold]
```

Catch bugs **before** runtime. Document intent.
:::

::: {.column width="50%"}
### Two tools, two purposes

| Tool | Use Case |
|------|----------|
| **Pyright** | Local dev (fast, strict) |
| **mypy** | CI/pre-commit (stable) |

```bash
# Fast feedback while coding
pixi run typecheck      # pyright

# Stable checks in CI
pixi run typecheck-ci   # mypy
```
:::
:::

## Pyright: Fast Local Feedback

::: {.columns}
::: {.column width="50%"}
### Speed matters

- Written in TypeScript
- Checks large codebases in seconds
- Excellent VS Code integration (Pylance)

### Strict mode available

```bash
pixi run typecheck-strict
```

Catches more issues but requires more annotations.
:::

::: {.column width="50%"}
### VS Code integration

```json
// .vscode/settings.json
{
  "python.analysis.typeCheckingMode": "basic",
  "python.analysis.diagnosticMode": "workspace"
}
```

Real-time feedback as you type.

Hover over variables to see inferred types.
:::
:::

## mypy: Stable CI Checks

::: {.columns}
::: {.column width="50%"}
### Why mypy for CI?

- Battle-tested, stable
- Extensive plugin ecosystem
- Well-documented error messages
- Industry standard

### Configuration in pyproject.toml

```toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
```
:::

::: {.column width="50%"}
### Pre-commit integration

```yaml
# .pre-commit-config.yaml
- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.8.0
  hooks:
    - id: mypy
      additional_dependencies:
        - numpy
        - polars
```

Runs on every commit. No type errors reach main.
:::
:::

## Why Pydantic?

::: {.columns}
::: {.column width="50%"}
### The problem

```python
# Manual validation is tedious and error-prone
def run_experiment(config: dict) -> None:
    if "n_samples" not in config:
        raise ValueError("Missing n_samples")
    if not isinstance(config["n_samples"], int):
        raise TypeError("n_samples must be int")
    if config["n_samples"] < 1:
        raise ValueError("n_samples must be >= 1")
    # ... and so on for every field
```
:::

::: {.column width="50%"}
### Pydantic solution

```python
from pydantic import BaseModel, Field

class ExperimentConfig(BaseModel):
    n_samples: int = Field(ge=1)
    n_tune: int = Field(ge=1, default=500)
    random_seed: int | None = None
    output_dir: Path = Path("results")

# Validation happens automatically
config = ExperimentConfig(n_samples=1000)
```

**Automatic:** Type coercion, validation, serialization
:::
:::

## Pydantic for Scientific Configs

::: {.columns}
::: {.column width="50%"}
### Define once, validate everywhere

```python
from pydantic import BaseModel, Field
from pathlib import Path

class KalmanConfig(BaseModel):
    """Configuration for Kalman filter."""

    # Simulation parameters
    n_steps: int = Field(ge=10, le=10000)
    process_noise: float = Field(gt=0, le=10)
    measurement_noise: float = Field(gt=0, le=10)

    # Inference parameters
    n_samples: int = Field(ge=100, default=1000)
    n_tune: int = Field(ge=50, default=500)
```
:::

::: {.column width="50%"}
### Benefits

- **Type coercion:** `"1000"` becomes `1000`
- **Validation:** Catches invalid values immediately
- **Serialization:** `config.model_dump_json()`
- **Documentation:** Fields are self-documenting

### Load from YAML/JSON

```python
import yaml

with open("config.yaml") as f:
    data = yaml.safe_load(f)

config = KalmanConfig(**data)
```
:::
:::

## Pydantic + Type Checkers

```python
from pydantic import BaseModel, Field
import numpy as np
from numpy.typing import NDArray

class SimulationResult(BaseModel):
    """Results from a simulation run."""

    model_config = {"arbitrary_types_allowed": True}

    true_states: NDArray[np.float64]
    observations: NDArray[np.float64]
    config: KalmanConfig

    @property
    def n_steps(self) -> int:
        return len(self.true_states)
```

**Key insight:** Type hints + Pydantic = defense in depth

- **mypy/Pyright** catch type errors at development time
- **Pydantic** catches validation errors at runtime

## Hypothesis: Property-Based Testing

::: {.columns}
::: {.column width="50%"}
### The problem with example-based tests

```python
# You pick the examples
def test_sort():
    assert sort([3, 1, 2]) == [1, 2, 3]
    assert sort([]) == []
    assert sort([1]) == [1]
    # Did you think of all edge cases?
```

You test what you think of. Bugs hide in what you don't.
:::

::: {.column width="50%"}
### Hypothesis generates test cases

```python
from hypothesis import given, strategies as st

@given(st.lists(st.integers()))
def test_sort_properties(xs):
    result = sort(xs)
    # Property: length preserved
    assert len(result) == len(xs)
    # Property: sorted order
    assert all(a <= b for a, b in zip(result, result[1:]))
    # Property: same elements
    assert sorted(xs) == result
```
:::
:::

## Hypothesis Strategies

::: {.columns}
::: {.column width="50%"}
### Built-in strategies

```python
from hypothesis import strategies as st

# Primitives
st.integers(min_value=0, max_value=100)
st.floats(allow_nan=False)
st.text(min_size=1)
st.booleans()

# Collections
st.lists(st.integers(), min_size=1)
st.dictionaries(st.text(), st.integers())

# Combine them
st.tuples(st.integers(), st.text())
```
:::

::: {.column width="50%"}
### NumPy arrays

```python
from hypothesis.extra.numpy import arrays
import numpy as np

@given(arrays(
    dtype=np.float64,
    shape=st.tuples(
        st.integers(1, 100),
        st.integers(1, 10),
    ),
    elements=st.floats(-1e6, 1e6, allow_nan=False),
))
def test_matrix_properties(arr):
    # Test with random matrices
    assert arr.shape[0] >= 1
```
:::
:::

## Hypothesis in Practice

```python
from hypothesis import given, strategies as st, settings
import numpy as np

@given(
    n_steps=st.integers(min_value=10, max_value=100),
    process_noise=st.floats(min_value=0.01, max_value=1.0),
)
@settings(max_examples=50)  # Limit for slow tests
def test_kalman_filter_properties(n_steps, process_noise):
    """Test that Kalman filter has expected properties."""
    states, obs = simulate_noisy_trajectory(
        n_steps=n_steps,
        process_noise=process_noise,
        seed=42,
    )

    # Property: observations should be noisier than states
    assert np.std(obs) >= np.std(states) * 0.5

    # Property: lengths match
    assert len(states) == len(obs) == n_steps
```

**Key insight:** Test *properties* that must always hold, not specific values.

# Workflows & Quality {background-color="#F18F01"}

## Git for Researchers

::: {.columns}
::: {.column width="50%"}
### Feature branches

```bash
# Never commit directly to main
git checkout -b feature/add-filter

# Make changes, then
git add .
git commit -m "Add bandpass filter"

# Merge via pull request
git push -u origin feature/add-filter
```
:::

::: {.column width="50%"}
### Good commit messages

**Bad:**
```
fix
update
changes
```

**Good:**
```
fix: correct off-by-one in filter
feat: add bandpass filter option
docs: update installation guide
```
:::
:::

## Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-mypy
    hooks:
      - id: mypy
```

**What happens:**

1. You run `git commit`
2. Pre-commit runs Ruff and mypy
3. If issues found → commit blocked, auto-fixed
4. You commit again → clean code only

## GitHub Actions CI

```yaml
# .github/workflows/ci.yml
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: prefix-dev/setup-pixi@v0.8.1
      - run: pixi run test
      - run: pixi run lint
      - run: pixi run typecheck
```

Every push triggers automated testing.

**Badge on README = instant trust.**

## CI: Resource-Efficient Testing

![](images/ci-dependency-graph.png){height="500px"}

Parallel jobs with smart dependencies — fast feedback, minimal compute.

## CI: This is Trust

![](images/ci-passing.png){height="450px"}

**Add features. Don't worry about breaking something.**

When CI passes, you know it works.

## Quality Isn't Optional. It's Automated.

::: {.columns}
::: {.column width="50%"}
### Test Coverage (pytest-cov)

```
Name                         Cover
-------------------------------
__init__.py                   100%
data/simulate.py              100%
inference/diagnostics.py       93%
inference/kalman.py           100%
-------------------------------
TOTAL                          97%

✓ Required coverage 70% reached
```
:::
::: {.column width="50%"}
### Docstring Coverage (interrogate)

```
Name                         Cover%
-------------------------------
__init__.py                   100%
data/simulate.py              100%
inference/diagnostics.py      100%
inference/kalman.py           100%
-------------------------------
TOTAL                        94.4%

✓ PASSED (minimum: 80%)
```
:::
:::

**Low friction, high standards.** Runs automatically on every push.

## The Development Loop

```{mermaid}
flowchart LR
    A[Branch] --> B[Code]
    B --> C[Test]
    C --> D[Commit]
    D --> E[Push]
    E --> F[PR]
    F --> G[Review]
    G --> H[Merge]
    H --> A
```

1. Create feature branch
2. Write code + tests
3. Run `pixi run check`
4. Commit (pre-commit runs)
5. Push and create PR
6. CI runs, review, merge

## Fork and Customize

::: {.columns}
::: {.column width="50%"}
### Steps

1. **Fork** this repository
2. **Rename** `hive_protocol` → your project
3. **Update** `pyproject.toml` metadata
4. **Replace** the Kalman filter with your code
5. **Keep** testing + CI patterns
:::

::: {.column width="50%"}
### What to keep

- `src/` layout
- `pyproject.toml` structure
- Test organization
- CI/CD workflows
- Pre-commit configuration
- Quarto notebooks pattern
:::
:::

## Hands-on: Make a Change

```bash
# Create branch
git checkout -b demo/my-feature

# Edit something (e.g., add a docstring)
# ...

# Run checks
pixi run check

# Commit
git add .
git commit -m "docs: add docstring to function"

# Watch pre-commit run!

# Push
git push -u origin demo/my-feature
```

# Hands-On Demos {background-color="#F18F01"}

## Demo: Ruff Auto-Fix

::: {.columns}
::: {.column width="50%"}
### Before

```python
import numpy as np
import os,sys
from typing import List,Dict
def bad_func(x,y,z):
    result=x+y
    unused_var = 10
    return result
```

### Commands

```bash
pixi run ruff check --fix demo.py
pixi run ruff format demo.py
```
:::

::: {.column width="50%"}
### After

```python
import numpy as np


def bad_func(x, y, z):
    result = x + y
    return result
```

**Fixed automatically:**

- Removed unused imports (`os`, `sys`)
- Fixed spacing around operators
- Removed unused variable
- Sorted and cleaned imports
:::
:::

## Demo: Quarto Live Edit

::: {.columns}
::: {.column width="50%"}
### Start the preview server

```bash
quarto preview notebooks/01_introduction.qmd
```

### What you see

- Live reload on save
- Code + output rendered together
- Clean markdown source (git-friendly!)
:::

::: {.column width="50%"}
### The `.qmd` file

````markdown
---
title: "My Analysis"
---

## Introduction

Some text explaining the analysis.

```{{python}}
import numpy as np
x = np.linspace(0, 10, 100)
print(f"Created {len(x)} points")
```

Results appear inline!
````
:::
:::

## Demo: Pydantic Validation

```python
from pydantic import BaseModel, Field, ValidationError

class ExperimentConfig(BaseModel):
    n_samples: int = Field(ge=1, le=10000)
    learning_rate: float = Field(gt=0, lt=1)

# Valid config
config = ExperimentConfig(n_samples=1000, learning_rate=0.01)
print(config)  # n_samples=1000 learning_rate=0.01

# Invalid config - clear error message!
try:
    bad = ExperimentConfig(n_samples=-5, learning_rate=2.0)
except ValidationError as e:
    print(e)
    # n_samples: Input should be >= 1
    # learning_rate: Input should be < 1
```

**Your experiments fail fast with clear messages.**

## Demo: Hypothesis Bug Finding

```python
from hypothesis import given, strategies as st

def remove_duplicates(items: list[int]) -> list[int]:
    """Remove duplicates while preserving order."""
    seen = set()
    return [x for x in items if x not in seen and not seen.add(x)]

@given(st.lists(st.integers()))
def test_remove_duplicates(items):
    result = remove_duplicates(items)
    # Property: no duplicates
    assert len(result) == len(set(result))
    # Property: all elements preserved
    assert set(result) == set(items)
    # Property: order preserved
    for i, x in enumerate(result):
        original_idx = items.index(x)
        assert all(items.index(y) > original_idx for y in result[i+1:] if y != x)
```

Run: `pixi run pytest -v` — Hypothesis generates hundreds of test cases automatically.

# Summary {background-color="#2E86AB"}

## What We Covered

| Topic | Key Takeaway |
|-------|--------------|
| Foundations | Pixi + Ruff for 10-100x speedup |
| Type Safety | Pyright for local dev, mypy for CI |
| Configuration | Pydantic validates your experiment parameters |
| Testing | Hypothesis finds bugs you didn't think of |
| Coverage | pytest-cov + interrogate automate quality |
| Workflows | CI/CD catches issues before they reach main |

## Resources

- **Repository:** [github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
- **Pixi:** [pixi.sh](https://pixi.sh)
- **Ruff:** [docs.astral.sh/ruff](https://docs.astral.sh/ruff)
- **Pydantic:** [docs.pydantic.dev](https://docs.pydantic.dev)
- **Hypothesis:** [hypothesis.readthedocs.io](https://hypothesis.readthedocs.io)
- **pytest-cov:** [pytest-cov.readthedocs.io](https://pytest-cov.readthedocs.io)
- **Interrogate:** [interrogate.readthedocs.io](https://interrogate.readthedocs.io)

## Next Steps

1. **Today:** Fork the repository
2. **This week:** Adapt it to your project
3. **Ongoing:** Share with your lab

. . .

::: {.center}
[⬢ HIVE-PROTOCOL ⬢]{.hive-brand .hive-brand-small}
:::

**Questions?**

[github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
