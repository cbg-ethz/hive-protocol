---
title: "Modern Python for Computational Biology"
subtitle: "The Hive Protocol"
author: "CBG Retreat 2026"
date: "January 2026"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    transition: fade
    width: 1600
    height: 900
    footer: "CBG Retreat 2026 | ETH Zurich"
execute:
  echo: true
  eval: false
---

# Foundations {background-color="#2E86AB"}

## The Problem

::: {.columns}
::: {.column width="50%"}
### What we see in research code

- `requirements.txt` with version conflicts
- No tests ("I tested it manually")
- No type hints
- "Works on my machine"
- Jupyter notebooks in git (merge nightmare)
:::

::: {.column width="50%"}
### The cost

- Hours debugging environment issues
- Results that can't be reproduced
- Code that only the author understands
- Papers with broken supplementary code
:::
:::

## The 2025 Landscape

The Python ecosystem has matured. **Use the modern tools.**

| Old Way | Modern Way | Benefit |
|---------|------------|---------|
| pip + requirements.txt | **pixi** | 10-100x faster, handles conda + PyPI |
| Black + flake8 + isort | **Ruff** | Single tool, 30-100x faster |
| pandas for everything | **Polars** | 5-50x faster for large data |
| Jupyter notebooks | **Quarto** | Clean git diffs, reproducible |
| Manual testing | **pytest + Hypothesis** | Property-based testing |

## Why Pixi?

::: {.columns}
::: {.column width="60%"}
### Bioinformatics needs conda

- samtools, bedtools, bcftools
- Many tools are conda-only
- PyPI alone isn't enough

### Pixi handles both

```bash
# Install everything in seconds
pixi install

# Run commands in the environment
pixi run test
pixi run lint
```
:::

::: {.column width="40%"}
### Speed comparison

```
Traditional setup:
  conda create ... → 5 min
  pip install ... → 2 min
  conflicts ... → 30 min

Pixi:
  pixi install → 30 sec
```
:::
:::

## Why Ruff?

::: {.columns}
::: {.column width="50%"}
### One tool replaces many

- Black (formatting)
- flake8 (linting)
- isort (import sorting)
- pyupgrade (syntax updates)
- And 700+ lint rules

### Written in Rust

30-100x faster than Python equivalents
:::

::: {.column width="50%"}
### Demo

```bash
# Check for issues
pixi run ruff check src/

# Auto-fix everything
pixi run ruff check --fix src/
pixi run ruff format src/
```

One command. Done.
:::
:::

## Repository Structure

```
hive-protocol/
├── src/hive_protocol/       # Source code (src layout)
│   ├── inference/           # Kalman filter + diagnostics
│   └── data/                # Data simulation
├── tests/                   # pytest + Hypothesis tests
├── notebooks/               # Quarto tutorials
├── workflow/                # Snakemake pipeline
├── docs/                    # Workshop materials
├── pyproject.toml           # Single source of truth
└── pixi.toml                # Environment specification
```

**Key principle:** `pyproject.toml` is the single source of truth for your project.

## Hands-on: Setup

```bash
# Clone the repository
git clone https://github.com/cbg-ethz/hive-protocol.git
cd hive-protocol

# Install pixi (if needed)
curl -fsSL https://pixi.sh/install.sh | bash

# Set up environment
pixi install

# Verify it works
pixi run test
```

**Goal:** Everyone has a working environment.

# Example Content: Bayesian Kalman Filter {background-color="#A23B72"}

## The Example: State-Space Model

::: {.columns}
::: {.column width="50%"}
### The problem

Estimate hidden states from noisy observations using PyMC.

```python
from hive_protocol.data import simulate_noisy_trajectory
from hive_protocol.inference import fit_kalman_filter

# Simulate and fit
states, obs = simulate_noisy_trajectory(n_steps=50)
model, trace = fit_kalman_filter(obs)
```

*This is example content—replace with your domain logic.*
:::

::: {.column width="50%"}
### Always check diagnostics

- **R-hat** < 1.01: Chains converged
- **ESS** > 400: Enough samples
- **Divergences** = 0: No issues

> "If you don't check diagnostics, you don't have results."
:::
:::

# Testing & Type Safety {background-color="#A23B72"}

## Type Checking: mypy vs Pyright

::: {.columns}
::: {.column width="50%"}
### Why type hints?

```python
# Without types - what does this return?
def process(data, threshold):
    return [x for x in data if x > threshold]

# With types - crystal clear
def process(
    data: list[float],
    threshold: float,
) -> list[float]:
    return [x for x in data if x > threshold]
```

Catch bugs **before** runtime. Document intent.
:::

::: {.column width="50%"}
### Two tools, two purposes

| Tool | Use Case |
|------|----------|
| **Pyright** | Local dev (fast, strict) |
| **mypy** | CI/pre-commit (stable) |

```bash
# Fast feedback while coding
pixi run typecheck      # pyright

# Stable checks in CI
pixi run typecheck-ci   # mypy
```
:::
:::

## Pyright: Fast Local Feedback

::: {.columns}
::: {.column width="50%"}
### Speed matters

- Written in TypeScript
- Checks large codebases in seconds
- Excellent VS Code integration (Pylance)

### Strict mode available

```bash
pixi run typecheck-strict
```

Catches more issues but requires more annotations.
:::

::: {.column width="50%"}
### VS Code integration

```json
// .vscode/settings.json
{
  "python.analysis.typeCheckingMode": "basic",
  "python.analysis.diagnosticMode": "workspace"
}
```

Real-time feedback as you type.

Hover over variables to see inferred types.
:::
:::

## mypy: Stable CI Checks

::: {.columns}
::: {.column width="50%"}
### Why mypy for CI?

- Battle-tested, stable
- Extensive plugin ecosystem
- Well-documented error messages
- Industry standard

### Configuration in pyproject.toml

```toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
```
:::

::: {.column width="50%"}
### Pre-commit integration

```yaml
# .pre-commit-config.yaml
- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.8.0
  hooks:
    - id: mypy
      additional_dependencies:
        - numpy
        - polars
```

Runs on every commit. No type errors reach main.
:::
:::

## Hypothesis: Property-Based Testing

::: {.columns}
::: {.column width="50%"}
### The problem with example-based tests

```python
# You pick the examples
def test_sort():
    assert sort([3, 1, 2]) == [1, 2, 3]
    assert sort([]) == []
    assert sort([1]) == [1]
    # Did you think of all edge cases?
```

You test what you think of. Bugs hide in what you don't.
:::

::: {.column width="50%"}
### Hypothesis generates test cases

```python
from hypothesis import given, strategies as st

@given(st.lists(st.integers()))
def test_sort_properties(xs):
    result = sort(xs)
    # Property: length preserved
    assert len(result) == len(xs)
    # Property: sorted order
    assert all(a <= b for a, b in zip(result, result[1:]))
    # Property: same elements
    assert sorted(xs) == result
```
:::
:::

## Hypothesis Strategies

::: {.columns}
::: {.column width="50%"}
### Built-in strategies

```python
from hypothesis import strategies as st

# Primitives
st.integers(min_value=0, max_value=100)
st.floats(allow_nan=False)
st.text(min_size=1)
st.booleans()

# Collections
st.lists(st.integers(), min_size=1)
st.dictionaries(st.text(), st.integers())

# Combine them
st.tuples(st.integers(), st.text())
```
:::

::: {.column width="50%"}
### NumPy arrays

```python
from hypothesis.extra.numpy import arrays
import numpy as np

@given(arrays(
    dtype=np.float64,
    shape=st.tuples(
        st.integers(1, 100),
        st.integers(1, 10),
    ),
    elements=st.floats(-1e6, 1e6, allow_nan=False),
))
def test_matrix_properties(arr):
    # Test with random matrices
    assert arr.shape[0] >= 1
```
:::
:::

## Hypothesis in Practice

```python
from hypothesis import given, strategies as st, settings
import numpy as np

@given(
    n_steps=st.integers(min_value=10, max_value=100),
    process_noise=st.floats(min_value=0.01, max_value=1.0),
)
@settings(max_examples=50)  # Limit for slow tests
def test_kalman_filter_properties(n_steps, process_noise):
    """Test that Kalman filter has expected properties."""
    states, obs = simulate_noisy_trajectory(
        n_steps=n_steps,
        process_noise=process_noise,
        seed=42,
    )

    # Property: observations should be noisier than states
    assert np.std(obs) >= np.std(states) * 0.5

    # Property: lengths match
    assert len(states) == len(obs) == n_steps
```

**Key insight:** Test *properties* that must always hold, not specific values.

# Workflows & Quality {background-color="#F18F01"}

## Git for Researchers

::: {.columns}
::: {.column width="50%"}
### Feature branches

```bash
# Never commit directly to main
git checkout -b feature/add-filter

# Make changes, then
git add .
git commit -m "Add bandpass filter"

# Merge via pull request
git push -u origin feature/add-filter
```
:::

::: {.column width="50%"}
### Good commit messages

**Bad:**
```
fix
update
changes
```

**Good:**
```
fix: correct off-by-one in filter
feat: add bandpass filter option
docs: update installation guide
```
:::
:::

## Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-mypy
    hooks:
      - id: mypy
```

**What happens:**

1. You run `git commit`
2. Pre-commit runs Ruff and mypy
3. If issues found → commit blocked, auto-fixed
4. You commit again → clean code only

## GitHub Actions CI

```yaml
# .github/workflows/ci.yml
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: prefix-dev/setup-pixi@v0.8.1
      - run: pixi run test
      - run: pixi run lint
      - run: pixi run typecheck
```

Every push triggers automated testing.

**Badge on README = instant trust.**

## The Development Loop

```{mermaid}
flowchart LR
    A[Branch] --> B[Code]
    B --> C[Test]
    C --> D[Commit]
    D --> E[Push]
    E --> F[PR]
    F --> G[Review]
    G --> H[Merge]
    H --> A
```

1. Create feature branch
2. Write code + tests
3. Run `pixi run check`
4. Commit (pre-commit runs)
5. Push and create PR
6. CI runs, review, merge

## Fork and Customize

::: {.columns}
::: {.column width="50%"}
### Steps

1. **Fork** this repository
2. **Rename** `hive_protocol` → your project
3. **Update** `pyproject.toml` metadata
4. **Replace** the Kalman filter with your code
5. **Keep** testing + CI patterns
:::

::: {.column width="50%"}
### What to keep

- `src/` layout
- `pyproject.toml` structure
- Test organization
- CI/CD workflows
- Pre-commit configuration
- Quarto notebooks pattern
:::
:::

## Hands-on: Make a Change

```bash
# Create branch
git checkout -b demo/my-feature

# Edit something (e.g., add a docstring)
# ...

# Run checks
pixi run check

# Commit
git add .
git commit -m "docs: add docstring to function"

# Watch pre-commit run!

# Push
git push -u origin demo/my-feature
```

# Summary {background-color="#2E86AB"}

## What We Covered

| Topic | Key Takeaway |
|-------|--------------|
| Foundations | Use pixi + Ruff for 10-100x speedup |
| Type Safety | Pyright for local dev, mypy for CI |
| Testing | Hypothesis finds bugs you didn't think of |
| Workflows | Automate quality with CI/CD |

## Resources

- **Repository:** [github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
- **Tutorial:** `docs/TUTORIAL.md`
- **Pixi:** [pixi.sh](https://pixi.sh)
- **Ruff:** [docs.astral.sh/ruff](https://docs.astral.sh/ruff)
- **Hypothesis:** [hypothesis.readthedocs.io](https://hypothesis.readthedocs.io)
- **Pyright:** [github.com/microsoft/pyright](https://github.com/microsoft/pyright)

## Next Steps

1. **Today:** Fork the repository
2. **This week:** Adapt it to your project
3. **Ongoing:** Share with your lab

. . .

**Questions?**

[github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
