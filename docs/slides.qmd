---
title: "Modern Python for Computational Biology"
subtitle: "‚¨¢ The Hive Protocol ‚¨¢"
author: "Gordon J. Koehn | CBG Retreat 2026"
date: "22 January 2026"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    transition: fade
    width: 1600
    height: 900
    footer: "‚¨¢ Hive Protocol ‚¨¢ CBG Retreat 2026 | ETH Zurich"
execute:
  echo: true
  eval: false
---

## {background-color="#2E86AB"}

::: {.r-fit-text}
What if every project started with tests, docs, and CI already working?
:::

. . .

**Fork this repo. Delete the TODO. Ship research software.**

. . .

::: {.red-queen-quote}
![](images/red-queen.png){height="120px"}
*"It takes all the running you can do, to keep in the same place..."*
:::

::: {.center}
[‚¨¢ HIVE-PROTOCOL ‚¨¢]{.hive-brand .hive-brand-large}
:::


## The Problem

::: {.columns}
::: {.column width="55%"}
![](images/xkcd-fixing-problems.png){height="400px"}
:::

::: {.column width="45%"}
### The recursive refactor trap

- "Just one quick fix..."
- No tests ‚Üí afraid to change code
- No types ‚Üí bugs hide until runtime
- No CI ‚Üí "works on my machine"
- No structure ‚Üí rewrite from scratch

### The real cost

- **Papers** with broken code
- **Results** that can't be reproduced
- **Time** lost to environment hell
:::
:::

# Foundations {background-color="#2E86AB"}

## The 2026 Landscape

The Python ecosystem has matured. **Use the modern tools.**

:::: {.columns}
::: {.column width="50%"}
| Function | ~~The Old Way~~ |
|----------|-----------------|
| Package Mgmt | pip + requirements.txt |
| Code Quality | Black + flake8 + isort |
| Data Processing | pandas for everything |
| Literate Prog. | Jupyter notebooks |
| Testing | Manual test cases |
| Config Validation | Manual checks |
:::

::: {.column width="50%" .fragment}
| | **The Modern Way** |
|:---:|-------------------|
| ‚Üí | **pixi** |
| ‚Üí | **Ruff** |
| ‚Üí | **Polars** |
| ‚Üí | **Quarto** |
| ‚Üí | **pytest + Hypothesis** |
| ‚Üí | **Pydantic** |

**All included in this template!**
:::
::::

## Our Toolkit

::: {.honeycomb}
::: {.hex-row .row-top}
::: {.hex-item}
![](images/logos/pixi.svg){height="45px"}
Pixi
:::
::: {.hex-item}
![](images/logos/ruff.svg){height="45px"}
Ruff
:::
::: {.hex-item}
![](images/logos/polars.svg){height="45px"}
Polars
:::
::: {.hex-item}
![](images/logos/quarto.svg){height="45px"}
Quarto
:::
:::
::: {.hex-row .row-middle}
::: {.hex-item}
![](images/logos/pytest.svg){height="45px"}
Pytest
:::
::: {.hex-item}
![](images/logos/hypothesis.svg){height="45px"}
Hypothesis
:::
::: {.hex-item}
![](images/logos/pydantic.svg){height="45px"}
Pydantic
:::
:::
::: {.hex-row .row-bottom}
::: {.hex-item}
![](images/logos/mypy.svg){height="45px"}
mypy
:::
::: {.hex-item}
![](images/logos/pyright.svg){height="45px"}
Pyright
:::
::: {.hex-item}
![](images/logos/interrogate.svg){height="45px"}
Interrogate
:::
:::
:::

## Why Pixi?

::: {.columns}
::: {.column width="55%"}
### Bioinformatics needs conda

- samtools, bedtools, bcftools
- Many tools are conda-only
- PyPI alone isn't enough

### The alternatives

| Tool | Conda | PyPI | Speed | Lock files |
|------|:-----:|:----:|:-----:|:----------:|
| **conda** | Yes | Limited | Slow | No |
| **poetry** | No | Yes | Medium | Yes |
| **uv** | No | Yes | Fast | Yes |
| **pixi** | Yes | Yes | Fast | Yes |

:::

::: {.column width="45%"}
### Why we chose Pixi

```bash
# Install everything in seconds
pixi install

# Run commands in the environment
pixi run test
pixi run lint
```

### Speed comparison

```
conda create ... ‚Üí 5 min
poetry install ‚Üí 2 min
uv pip install ‚Üí 30 sec
pixi install ‚Üí 30 sec
  (+ conda packages!)
```
:::
:::

## Pixi: Community Support

::: {.columns}
::: {.column width="33%"}
![](images/conda-forge-pixi.png){height="320px"}
:::
::: {.column width="33%"}
![](images/anaconda-pixi.png){height="320px"}
:::
::: {.column width="33%"}
![](images/pixi-star-history.png){height="320px"}
:::
:::

Endorsed by **conda-forge** and **Anaconda** ‚Äî the future of conda environments.

::: {.callout-note}
**Free for research:** Pixi is BSD3-licensed. No fees, no restrictions on academic use.
:::

## Why Ruff?

::: {.columns}
::: {.column width="50%"}
### One tool replaces many

- Black (formatting)
- flake8 (linting)
- isort (import sorting)
- pyupgrade (syntax updates)
- And 700+ lint rules

### Written in Rust

30-100x faster than Python equivalents
:::

::: {.column width="50%"}
### Demo

```bash
# Check for issues
pixi run ruff check src/

# Auto-fix everything
pixi run ruff check --fix src/
pixi run ruff format src/
```

One command. Done.
:::
:::

## Repository Structure

```
hive-protocol/
‚îú‚îÄ‚îÄ src/hive_protocol/       # Source code (src layout)
‚îÇ   ‚îú‚îÄ‚îÄ inference/           # Kalman filter + diagnostics
‚îÇ   ‚îî‚îÄ‚îÄ data/                # Data simulation
‚îú‚îÄ‚îÄ tests/                   # pytest + Hypothesis tests
‚îú‚îÄ‚îÄ notebooks/               # Quarto tutorials
‚îú‚îÄ‚îÄ workflow/                # Snakemake pipeline
‚îú‚îÄ‚îÄ docs/                    # Workshop materials
‚îú‚îÄ‚îÄ pyproject.toml           # Single source of truth
‚îî‚îÄ‚îÄ pixi.toml                # Environment specification
```

**Key principle:** `pyproject.toml` is the single source of truth for your project.

## Hands-on: Setup

```bash
# Clone the repository
git clone https://github.com/cbg-ethz/hive-protocol.git
cd hive-protocol

# Install pixi (if needed)
curl -fsSL https://pixi.sh/install.sh | bash

# Set up environment
pixi install

# Verify it works
pixi run test
```

**Goal:** Everyone has a working environment.

# Example Content: Bayesian Kalman Filter {background-color="#A23B72"}

## The Example: State-Space Model

::: {.columns}
::: {.column width="50%"}
### The problem

Estimate hidden states from noisy observations using PyMC.

```python
from hive_protocol.data import simulate_noisy_trajectory
from hive_protocol.inference import fit_kalman_filter

# Simulate and fit
states, obs = simulate_noisy_trajectory(n_steps=50)
model, trace = fit_kalman_filter(obs)
```

*This is example content‚Äîreplace with your domain logic.*
:::

::: {.column width="50%"}
### Always check diagnostics

- **R-hat** < 1.01: Chains converged
- **ESS** > 400: Enough samples
- **Divergences** = 0: No issues

> "If you don't check diagnostics, you don't have results."
:::
:::

# Testing & Type Safety {background-color="#A23B72"}

## {background-color="#1a1a2e" .center}

::: {.meme-slide}

```{.python .meme-code}
üöó = "Toyota Corolla 2021"
üöó_number = float(üöó)
üöó_number
>>> 34783
```

::: {.fragment .meme-caption}
*"Python lets you do this at 3am. Type checkers stop you at 9am."*
:::
:::

## Type Checking: mypy vs Pyright

::: {.columns}
::: {.column width="50%"}
### Why type hints?

```python
# Without types - what does this return?
def process(data, threshold):
    return [x for x in data if x > threshold]

# With types - crystal clear
def process(
    data: list[float],
    threshold: float,
) -> list[float]:
    return [x for x in data if x > threshold]
```

Catch bugs **before** runtime. Document intent.
:::

::: {.column width="50%"}
### Two tools, two purposes

| Tool | Use Case |
|------|----------|
| **Pyright** | Local dev (fast, strict) |
| **mypy** | CI only (stable, canonical) |

```bash
# Fast feedback while coding
pixi run typecheck      # pyright

# Stable checks in CI
pixi run typecheck-ci   # mypy
```
:::
:::

## Pyright: Fast Local Feedback

::: {.columns}
::: {.column width="50%"}
### Speed matters

- Written in TypeScript
- Checks large codebases in seconds
- Excellent VS Code integration (Pylance)

### Strict mode available

```bash
pixi run typecheck-strict
```

Catches more issues but requires more annotations.
:::

::: {.column width="50%"}
### VS Code integration

```json
// .vscode/settings.json
{
  "python.analysis.typeCheckingMode": "basic",
  "python.analysis.diagnosticMode": "workspace"
}
```

Real-time feedback as you type.

Hover over variables to see inferred types.
:::
:::

## mypy: Stable CI Checks

::: {.columns}
::: {.column width="50%"}
### Why mypy for CI?

- Battle-tested, stable
- Extensive plugin ecosystem
- Well-documented error messages
- Industry standard

### Configuration in pyproject.toml

```toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
```
:::

::: {.column width="50%"}
### CI integration

```yaml
# .github/workflows/ci.yml
- name: Run mypy
  run: pixi run typecheck-ci
```

```bash
# pixi.toml task
typecheck-ci = "mypy src/"
```

Runs on every PR. No type errors reach main.
:::
:::

## Why Pydantic?

::: {.columns}
::: {.column width="50%"}
### The problem

```python
# Manual validation is tedious and error-prone
def run_experiment(config: dict) -> None:
    if "n_samples" not in config:
        raise ValueError("Missing n_samples")
    if not isinstance(config["n_samples"], int):
        raise TypeError("n_samples must be int")
    if config["n_samples"] < 1:
        raise ValueError("n_samples must be >= 1")
    # ... and so on for every field
```
:::

::: {.column width="50%"}
### Pydantic solution

```python
from pydantic import BaseModel, Field

class ExperimentConfig(BaseModel):
    n_samples: int = Field(ge=1)
    n_tune: int = Field(ge=1, default=500)
    random_seed: int | None = None
    output_dir: Path = Path("results")

# Validation happens automatically
config = ExperimentConfig(n_samples=1000)
```

**Automatic:** Type coercion, validation, serialization
:::
:::

## Pydantic for Scientific Configs

::: {.columns}
::: {.column width="50%"}
### Define once, validate everywhere

```python
from pydantic import BaseModel, Field
from pathlib import Path

class KalmanConfig(BaseModel):
    """Configuration for Kalman filter."""

    # Simulation parameters
    n_steps: int = Field(ge=10, le=10000)
    process_noise: float = Field(gt=0, le=10)
    measurement_noise: float = Field(gt=0, le=10)

    # Inference parameters
    n_samples: int = Field(ge=100, default=1000)
    n_tune: int = Field(ge=50, default=500)
```
:::

::: {.column width="50%"}
### Benefits

- **Type coercion:** `"1000"` becomes `1000`
- **Validation:** Catches invalid values immediately
- **Serialization:** `config.model_dump_json()`
- **Documentation:** Fields are self-documenting

### Load from YAML/JSON

```python
import yaml

with open("config.yaml") as f:
    data = yaml.safe_load(f)

config = KalmanConfig(**data)
```
:::
:::

## Pydantic + Type Checkers

```python
from pydantic import BaseModel, Field
import numpy as np
from numpy.typing import NDArray

class SimulationResult(BaseModel):
    """Results from a simulation run."""

    model_config = {"arbitrary_types_allowed": True}

    true_states: NDArray[np.float64]
    observations: NDArray[np.float64]
    config: KalmanConfig

    @property
    def n_steps(self) -> int:
        return len(self.true_states)
```

**Key insight:** Type hints + Pydantic = defense in depth

- **mypy/Pyright** catch type errors at development time
- **Pydantic** catches validation errors at runtime

## Hypothesis: Property-Based Testing

**Flip the playbook:** Don't write examples. Describe *properties* that must always hold.

&nbsp;

::: {.columns}
::: {.column width="50%"}
#### ‚ùå Example-based

```python
def test_sort():
    assert sort([3, 1, 2]) == [1, 2, 3]
    assert sort([]) == []
    assert sort([1]) == [1]
    # Did you think of all edge cases?
```

You test what you think of. Bugs hide in what you don't.
:::

::: {.column width="50%"}
#### ‚úì Property-based

```python
from hypothesis import given, strategies as st

@given(st.lists(st.integers()))
def test_sort_properties(xs):
    result = sort(xs)
    # Property: length preserved
    assert len(result) == len(xs)
    # Property: sorted order
    assert all(a <= b for a, b in zip(result, result[1:]))
```

Hypothesis generates **hundreds of random inputs** and finds the **minimal failing case**.
:::
:::

## Hypothesis Strategies

::: {.columns}
::: {.column width="50%"}
### Built-in strategies

```python
from hypothesis import strategies as st

# Primitives
st.integers(min_value=0, max_value=100)
st.floats(allow_nan=False)
st.text(min_size=1)
st.booleans()

# Collections
st.lists(st.integers(), min_size=1)
st.dictionaries(st.text(), st.integers())

# Combine them
st.tuples(st.integers(), st.text())
```
:::

::: {.column width="50%"}
### NumPy arrays

```python
from hypothesis.extra.numpy import arrays
import numpy as np

@given(arrays(
    dtype=np.float64,
    shape=st.tuples(
        st.integers(1, 100),
        st.integers(1, 10),
    ),
    elements=st.floats(-1e6, 1e6, allow_nan=False),
))
def test_matrix_properties(arr):
    # Test with random matrices
    assert arr.shape[0] >= 1
```
:::
:::

## Hypothesis in Practice

```python
from hypothesis import given, strategies as st, settings
import numpy as np

@given(
    n_steps=st.integers(min_value=10, max_value=100),
    process_noise=st.floats(min_value=0.01, max_value=1.0),
)
@settings(max_examples=50)  # Limit for slow tests
def test_kalman_filter_properties(n_steps, process_noise):
    """Test that Kalman filter has expected properties."""
    states, obs = simulate_noisy_trajectory(
        n_steps=n_steps,
        process_noise=process_noise,
        seed=42,
    )

    # Property: observations should be noisier than states
    assert np.std(obs) >= np.std(states) * 0.5

    # Property: lengths match
    assert len(states) == len(obs) == n_steps
```

**Key insight:** Test *properties* that must always hold, not specific values.

# Workflows & Quality {background-color="#F18F01"}

## Git for Researchers

```
main     ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè
              \             /
feature        ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè
               ‚Üë       ‚Üë   ‚Üë
            branch  commits  PR merge
```

::: {.columns}
::: {.column width="50%"}
### The workflow

```bash
git checkout -b feature/add-filter
# ... make changes ...
git add . && git commit -m "feat: add filter"
git push -u origin feature/add-filter
# Open PR ‚Üí CI runs ‚Üí review ‚Üí merge
```
:::

::: {.column width="50%"}
### Commit message format

```
<type>: <description>

fix:   bug fixes
feat:  new features
docs:  documentation
test:  adding tests
refactor: code changes
```
:::
:::

## Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
```

**What happens:**

1. You run `git commit`
2. Pre-commit runs Ruff (lint + format)
3. If issues found ‚Üí commit blocked, auto-fixed
4. You commit again ‚Üí clean code only

*Type checking (mypy) runs in CI to keep commits fast.*

## GitHub Actions CI

```yaml
# .github/workflows/ci.yml
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: prefix-dev/setup-pixi@v0.8.1
      - run: pixi run test
      - run: pixi run lint
      - run: pixi run typecheck
```

Every push triggers automated testing.

**Badge on README = instant trust.**

## CI: Resource-Efficient Testing

![](images/ci-dependency-graph.png){height="500px"}

Parallel jobs with smart dependencies ‚Äî fast feedback, minimal compute.

## CI: This is Trust

![](images/ci-passing.png){height="450px"}

**Add features. Don't worry about breaking something.**

When CI passes, you know it works.

## Quality Isn't Optional. It's Automated.

::: {.columns}
::: {.column width="50%"}
### Test Coverage (pytest-cov)

```
Name                         Cover
-------------------------------
__init__.py                   100%
data/simulate.py              100%
inference/diagnostics.py       93%
inference/kalman.py           100%
-------------------------------
TOTAL                          97%

‚úì Required coverage 70% reached
```
:::
::: {.column width="50%"}
### Docstring Coverage (interrogate)

```
Name                         Cover%
-------------------------------
__init__.py                   100%
data/simulate.py              100%
inference/diagnostics.py      100%
inference/kalman.py           100%
-------------------------------
TOTAL                        94.4%

‚úì PASSED (minimum: 80%)
```
:::
:::

**Low friction, high standards.** Runs automatically on every push.

## The Development Loop

```{mermaid}
flowchart LR
    A[Branch] --> B[Code]
    B --> C[Test]
    C --> D[Commit]
    D --> E[Push]
    E --> F[PR]
    F --> G[Review]
    G --> H[Merge]
    H --> A
```

1. Create feature branch
2. Write code + tests
3. Run `pixi run check`
4. Commit (pre-commit runs)
5. Push and create PR
6. CI runs, review, merge

## Fork and Customize

::: {.columns}
::: {.column width="50%"}
### Steps

1. **Fork** this repository
2. **Rename** `hive_protocol` ‚Üí your project
3. **Update** `pyproject.toml` metadata
4. **Replace** the Kalman filter with your code
5. **Keep** testing + CI patterns
:::

::: {.column width="50%"}
### What to keep

- `src/` layout
- `pyproject.toml` structure
- Test organization
- CI/CD workflows
- Pre-commit configuration
- Quarto notebooks pattern
:::
:::

# Hands-On Demos {background-color="#F18F01"}

## Demo: Ruff Auto-Fix

::: {.columns}
::: {.column width="50%"}
### Before

```python
import numpy as np
import os,sys
from typing import List,Dict
def bad_func(x,y,z):
    result=x+y
    unused_var = 10
    return result
```

### Commands

```bash
pixi run ruff check --fix messy_code.py
pixi run ruff format messy_code.py
```
:::

::: {.column width="50%"}
### After

```python
import numpy as np


def bad_func(x, y, z):
    result = x + y
    return result
```

**Fixed automatically:**

- Removed unused imports (`os`, `sys`)
- Fixed spacing around operators
- Removed unused variable
- Sorted and cleaned imports
:::
:::

## Demo: Quarto Live Edit

::: {.columns}
::: {.column width="50%"}
### Start the preview server

```bash
quarto preview notebooks/01_introduction.qmd
```

### What you see

- Live reload on save
- Code + output rendered together
- Clean markdown source (git-friendly!)
:::

::: {.column width="50%"}
### The `.qmd` file

````markdown
---
title: "My Analysis"
---

## Introduction

Some text explaining the analysis.

```{{python}}
import numpy as np
x = np.linspace(0, 10, 100)
print(f"Created {len(x)} points")
```

Results appear inline!
````
:::
:::

## Demo: Pydantic Validation

```python
from pydantic import BaseModel, Field, ValidationError

class ExperimentConfig(BaseModel):
    n_samples: int = Field(ge=1, le=10000)
    learning_rate: float = Field(gt=0, lt=1)

# Valid config
config = ExperimentConfig(n_samples=1000, learning_rate=0.01)
print(config)  # n_samples=1000 learning_rate=0.01

# Invalid config - clear error message!
try:
    bad = ExperimentConfig(n_samples=-5, learning_rate=2.0)
except ValidationError as e:
    print(e)
    # n_samples: Input should be >= 1
    # learning_rate: Input should be < 1
```

**Your experiments fail fast with clear messages.**

## Demo: Hypothesis Bug Finding

```python
from hypothesis import given, strategies as st

def remove_duplicates(items: list[int]) -> list[int]:
    """Remove duplicates while preserving order."""
    seen = set()
    return [x for x in items if x not in seen and not seen.add(x)]

@given(st.lists(st.integers()))
def test_remove_duplicates(items):
    result = remove_duplicates(items)
    # Property: no duplicates
    assert len(result) == len(set(result))
    # Property: all elements preserved
    assert set(result) == set(items)
    # Property: order preserved
    for i, x in enumerate(result):
        original_idx = items.index(x)
        assert all(items.index(y) > original_idx for y in result[i+1:] if y != x)
```

&nbsp;

```bash
pixi run pytest demos/demo_hypothesis.py -v --hypothesis-show-statistics
```

Watch Hypothesis generate **600 test cases** (200 per property) in under a second.

# Summary {background-color="#2E86AB"}

## What We Covered

| Topic | Key Takeaway |
|-------|--------------|
| Foundations | Pixi + Ruff for 10-100x speedup |
| Type Safety | Pyright for local dev, mypy for CI |
| Configuration | Pydantic validates your experiment parameters |
| Testing | Hypothesis finds bugs you didn't think of |
| Coverage | pytest-cov + interrogate automate quality |
| Workflows | CI/CD catches issues before they reach main |

## Resources

- **Repository:** [github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
- **Pixi:** [pixi.sh](https://pixi.sh)
- **Ruff:** [docs.astral.sh/ruff](https://docs.astral.sh/ruff)
- **Pydantic:** [docs.pydantic.dev](https://docs.pydantic.dev)
- **Hypothesis:** [hypothesis.readthedocs.io](https://hypothesis.readthedocs.io)
- **pytest-cov:** [pytest-cov.readthedocs.io](https://pytest-cov.readthedocs.io)
- **Interrogate:** [interrogate.readthedocs.io](https://interrogate.readthedocs.io)

## Next Steps

1. **Today:** Fork the repository
2. **This week:** Adapt it to your project
3. **Ongoing:** Share with your lab

. . .

::: {.center}
[‚¨¢ HIVE-PROTOCOL ‚¨¢]{.hive-brand .hive-brand-small}
:::

**Questions?**

[github.com/cbg-ethz/hive-protocol](https://github.com/cbg-ethz/hive-protocol)
